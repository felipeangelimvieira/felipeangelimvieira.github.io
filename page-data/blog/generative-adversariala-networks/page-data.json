{"componentChunkName":"component---src-templates-blog-post-js","path":"/blog/generative-adversariala-networks","webpackCompilationHash":"68e5e853c3047375e2b0","result":{"data":{"site":{"siteMetadata":{"title":"Felipe Angelim - Portfolio and blog","author":"Felipe Lourenço Angelim Vieira"}},"markdownRemark":{"id":"745b9d5a-c55c-54fa-b63b-4583b38a23fd","excerpt":"Feature Learning When we see a 4K movie in a television, we don't retain every pixel color. If asked about a scene, we'll point out some key informations about…","html":"<h1>Feature Learning</h1>\n<p>When we see a 4K movie in a television, we don't retain every pixel color. If asked about a scene, we'll point out some key informations about the number of children or adults, their poses and facial expressions. Likewise, in Feature Learning we want to compress an input into meaningful features - 16 millions of pixels into a low-dimensional vector, for example. Such vector could then be used for efficient storage or image manipulation.</p>\n<h1>Generative Adversarial Networks (GANs)</h1>\n<p>Generative Adversarial Networks are responsible for many of recent innovations in Machine Learning and the strategy behing their optimization is</p>\n<h1>Bidirectional GANs</h1>\n<p>\"Adversarial Feature Learning\", published at 2017 ICLR conference, proposes a framework for projecting images back into the latent space.</p>\n<p>The author's core idea is to introduce an Encoder network</p>\n<ul>\n<li>A converging GAN may not have a discriminator that learns useful features from the data. Near the equilibrium, the decoder do not depend on input X and predict P(y = 1) = 1/2.</li>\n</ul>","frontmatter":{"title":"Bidirectional GANs","date":"July 25, 2019"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/blog/hello-word/","previous":null,"next":null}}}
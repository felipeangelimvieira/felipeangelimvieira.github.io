{"componentChunkName":"component---src-templates-blog-post-js","path":"/blog/generative-adversarial-networks","webpackCompilationHash":"4c7a4e16bcfcef776e53","result":{"data":{"site":{"siteMetadata":{"title":"Felipe Angelim - Portfolio and blog","author":"Felipe Lourenço Angelim Vieira"}},"markdownRemark":{"id":"745b9d5a-c55c-54fa-b63b-4583b38a23fd","excerpt":"If I had to describe a Mondrian painting, I wouldn't remember its pixels. Instead, I would suggest the position of the lines and the color of the rectangles…","html":"<p>If I had to describe a Mondrian painting, I wouldn't remember its pixels. Instead, I would suggest the position of the lines and the color of the rectangles. Describing it pixel by pixel would be such a unnecessary task - we can simply take the most important features and save memory space in our brains.</p>\n<p>In feature learning, we train machine learning models to extract meaningful features from data. They usually have semantic sense and are more compact than the original input - the lines and colors rather than the pixels of a Mondrian painting. Given the complexity of natural images, this is not an easy task. Guaranteeing that the model won't focus on details such as hair and freckles in a face depends heavily on the function we are optimizing.\nIn autoencoders, for example, we minimize a pixelwise distance between the real and generated images. The model, therefore, captures minor details and doesn't prioritize the main content in images.</p>\n<p>Generative Adversarial Networks (GANs), on the other hand, have the potential to learn semantic features, as shown in <a href=\"https://arxiv.org/pdf/1605.09782.pdf\">Adversarial Feature Learning</a> paper in 2017. In this paper, the authors added an encoder to the vanilla GAN, forcing the discriminator to distinguish generator and encoder image-features pairs. GANs offer the advantage of making no assumption about the structure or type of data to which they are applied, leading to a more sophiscated feature extraction.</p>\n<h2>The BiGAN model</h2>\n<p>The network comprises three submodels: a generator G, an encoder E and a Discriminator D.\nThe generator creates an image from a latent space, while the encoder learns how to invert G and project the images back into that space. The discriminator asserts if an image-feature pair comes from the generator or the encoder. </p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/6b6b80c979ed570b710ed67e58865fe5/7315d/architecture.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 24%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAABJ0AAASdAHeZh94AAAAlklEQVQY03WOwRLDIAhE/f//bCdpY8eYKIKA3Y5tb+HgsMA+NziRj9F7F5Exhpptmcszejkhh/u4rmC1dlVmJiKcMsv62I/b4ufxN/sP0VqLMeac5yRcQH2egohEpRTQVTWltO87hpAfc2F1N8SeWrps6bVkJjEgzAyfwDYb4KYfL2Q4iE07i2ABMzW6b+uSauX+DXBdbwQjJZ2u9oGfAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Architecture image\"\n        title=\"Architecture image\"\n        src=\"/static/6b6b80c979ed570b710ed67e58865fe5/b9e4f/architecture.png\"\n        srcset=\"/static/6b6b80c979ed570b710ed67e58865fe5/cf440/architecture.png 148w,\n/static/6b6b80c979ed570b710ed67e58865fe5/d2d38/architecture.png 295w,\n/static/6b6b80c979ed570b710ed67e58865fe5/b9e4f/architecture.png 590w,\n/static/6b6b80c979ed570b710ed67e58865fe5/f9b6a/architecture.png 885w,\n/static/6b6b80c979ed570b710ed67e58865fe5/2d849/architecture.png 1180w,\n/static/6b6b80c979ed570b710ed67e58865fe5/7315d/architecture.png 1225w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n  </a>\n    </span></p>\n<p>The authors have also tested other tatics to extract features from the images, such as a latent regressor. This option, however, don't succeed as much as Bidirectional GAN when applied to complex datasets, such as ImageNet. They also point out that we can't use features from D.\nIf G and E converge, D is not able to distinguish their results and doesn't learn meaningful intermediate representations.</p>\n<p>The original GAN loss function V is:</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>V</mi><mo stretchy=\"false\">(</mo><mi>G</mi><mo separator=\"true\">,</mo><mi>D</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mi mathvariant=\"double-struck\">E</mi><mrow><mi>x</mi><mo>∼</mo><msub><mi>p</mi><mi>X</mi></msub></mrow></msub><mo stretchy=\"false\">[</mo><mi>log</mi><mo>⁡</mo><mi>D</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mspace linebreak=\"newline\"></mspace><mo>+</mo><msub><mi mathvariant=\"double-struck\">E</mi><mrow><mi>z</mi><mo>∼</mo><msub><mi>p</mi><mi>Z</mi></msub></mrow></msub><mo stretchy=\"false\">[</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>D</mi><mo stretchy=\"false\">(</mo><mi>G</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\"> V(G,D) = \\mathbb{E}_{x \\sim p_X}[\\log D(x)] \\\\ + \\mathbb{E}_{z \\sim p_Z}[\\log ( 1 - D(G(z)))]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">G</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"mrel mtight\">∼</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3567071428571427em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.07847em;\">X</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.14329285714285717em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"mrel mtight\">∼</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3567071428571427em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.07153em;\">Z</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.14329285714285717em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">G</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span></span></span></span></span>\n<p>where x is an image input and z is the latent space vector, and p their respective distributions. We can interpret V as a measure of D's accuracy. We optimize G and D through an adversarial objective <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mo><mi>min</mi><mo>⁡</mo></mo><mi>G</mi></msub><msub><mo><mi>max</mi><mo>⁡</mo></mo><mi>D</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\min_{G} \\max_{D}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.81786em;vertical-align:-0.15em;\"></span><span class=\"mop\"><span class=\"mop\">min</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">G</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop\">max</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">D</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> V(G,D). </p>\n<p>The new bidirectional GAN loss proposed in the paper is:</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>V</mi><mo stretchy=\"false\">(</mo><mi>G</mi><mo separator=\"true\">,</mo><mi>E</mi><mo separator=\"true\">,</mo><mi>D</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mi mathvariant=\"double-struck\">E</mi><mrow><mi>x</mi><mo>∼</mo><msub><mi>p</mi><mi>X</mi></msub></mrow></msub><mo stretchy=\"false\">[</mo><mi>log</mi><mo>⁡</mo><mi>D</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>E</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mspace linebreak=\"newline\"></mspace><mo>+</mo><msub><mi mathvariant=\"double-struck\">E</mi><mrow><mi>z</mi><mo>∼</mo><msub><mi>p</mi><mi>Z</mi></msub></mrow></msub><mo stretchy=\"false\">[</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>D</mi><mo stretchy=\"false\">(</mo><mi>G</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\"> V(G,E,D) = \\mathbb{E}_{x \\sim p_X}[\\log D(x,E(x))] \\\\ + \\mathbb{E}_{z \\sim p_Z}[\\log ( 1 - D(G(z), z))]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">G</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"mrel mtight\">∼</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3567071428571427em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.07847em;\">X</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.14329285714285717em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"mrel mtight\">∼</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3567071428571427em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.07153em;\">Z</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.14329285714285717em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">G</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span></span></span></span></span>\n<p>Now, the discriminator receives two inputs, and the min max objective is\n<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi>G</mi><mo separator=\"true\">,</mo><mi>E</mi></mrow></msub><msub><mo><mi>max</mi><mo>⁡</mo></mo><mi>D</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\min_{G,E} \\max_{D}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9539679999999999em;vertical-align:-0.286108em;\"></span><span class=\"mop\"><span class=\"mop\">min</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.328331em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">G</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05764em;\">E</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop\">max</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">D</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> V(G, E, D).</p>\n<h2>Results</h2>\n<p>The theoretical results were the most important contributions of the paper.\nFirst, the authors proved that the convergence occurs simultaneously for the encoder and generator when one learns to invert the other (<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>E</mi><mo>=</mo><msup><mi>G</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">E = G^{-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">G</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span> almost everywhere). As from the paper:</p>\n<blockquote>\n<p>The BiGAN objective forces the encoder, in order to fool the discrimator at a particular z, to invert the generator at that z, such that E(G(z)) = z</p>\n</blockquote>\n<p>The authors also presented interesting empirical results. The BiGAN features extracted from E(x) are useful for classification tasks, and overcome a latent regressor and D features when applied to complex datasets. For the MNIST, both performed similarly. The unsupervised encoder learnt filters similar to the ones of supervised models on ImageNet, and generalized well to detection and segmentation tasks too.</p>\n<h2>References</h2>\n<p>Donahue, J., Krähenbühl, P., &#x26; Darrell, T. (2016). Adversarial feature learning. arXiv preprint arXiv:1605.09782.</p>\n<p>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... &#x26; Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).</p>","frontmatter":{"title":"Bidirectional GANs for feature learning","date":"July 25, 2019"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/hello-word/","previous":null,"next":null}}}
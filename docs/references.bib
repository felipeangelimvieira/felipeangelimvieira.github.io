@article{Athanasopoulos2020,
abstract = {Accurate forecasts of macroeconomic variables are crucial inputs into the decisions of economic agents and policy makers. Exploiting inherent aggregation structures of such variables, we apply forecast reconciliation methods to generate forecasts that are coherent with the aggregation constraints. We generate both point and probabilistic forecasts for the first time in the macroeconomic setting. Using Australian GDP we show that forecast reconciliation not only returns coherent forecasts but also improves the overall forecast accuracy in both point and probabilistic frameworks.},
author = {Athanasopoulos, George and Gamakumara, Puwasala and Panagiotelis, Anastasios and Hyndman, Rob J. and Affan, Mohamed},
doi = {10.1007/978-3-030-31150-6_21},
file = {:C$\backslash$:/Users/felip/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Athanasopoulos et al. - 2020 - Hierarchical Forecasting.pdf:pdf},
issn = {22147977},
journal = {Advanced Studies in Theoretical and Applied Econometrics},
mendeley-groups = {Forecasting/Hierarchical Forecasting},
number = {February},
pages = {689--719},
title = {{Hierarchical Forecasting}},
volume = {52},
year = {2020}
}

@article{Panagiotelis2021,
abstract = {A geometric interpretation is developed for so-called reconciliation methodologies used to forecast time series that adhere to known linear constraints. In particular, a general framework is established that nests many existing popular reconciliation methods within the class of projections. This interpretation facilitates the derivation of novel theoretical results. First, reconciliation via projection is guaranteed to improve forecast accuracy with respect to a class of loss functions based on a generalised distance metric. Second, the Minimum Trace (MinT) method minimises expected loss for this same class of loss functions. Third, the geometric interpretation provides a new proof that forecast reconciliation using projections results in unbiased forecasts, provided that the initial base forecasts are also unbiased. Approaches for dealing with biased base forecasts are proposed. An extensive empirical study of Australian tourism flows demonstrates the theoretical results of the paper and shows that bias correction prior to reconciliation outperforms alternatives that only bias-correct or only reconcile forecasts.},
author = {Panagiotelis, Anastasios and Athanasopoulos, George and Gamakumara, Puwasala and Hyndman, Rob J.},
doi = {10.1016/j.ijforecast.2020.06.004},
file = {:C$\backslash$:/Users/felip/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Panagiotelis et al. - 2021 - Forecast reconciliation A geometric view with new insights on bias correction(2).pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Elliptical distributions,Forecast reconciliation,High-dimensional time series,Projections,Scoring rules},
mendeley-groups = {Forecasting/Hierarchical Forecasting},
number = {1},
pages = {343--359},
publisher = {Elsevier B.V.},
title = {{Forecast reconciliation: A geometric view with new insights on bias correction}},
url = {https://doi.org/10.1016/j.ijforecast.2020.06.004},
volume = {37},
year = {2021}
}

@article{Gross1990,
abstract = {This paper addresses the issue of forecasting individual items within a product line; where each line includes several independent but closely related products. The purpose of the research was to reduce the overall forecasting burden by developing and assessing schemes of disaggregating forecasts of a total product line to the related individual items. Measures were developed to determine appropriate disaggregated methodologies and to compare the forecast accuracy of individual product forecasts versus disaggregated totals. Several of the procedures used were based upon extensions of the combination of forecast research and applied to disaggregations of total forecasts of product lines. The objective was to identify situations when it was advantageous to produce disaggregated forecasts, and if advantageous, which method of disaggregation to utilize. This involved identification of the general conceptual characteristics within a set of product line data that might cause a disaggregation method to produce relatively accurate forecasts. These conceptual characteristics provided guidelines for forecasters on how to select a disaggregation method and under what conditions a particular method is applicable. Copyright {\textcopyright} 1990 John Wiley {\&} Sons, Ltd.},
author = {Gross, Charles W. and Sohl, Jeffrey E.},
doi = {10.1002/for.3980090304},
file = {:C$\backslash$:/Users/felip/OneDrive/Documentos/Artigos a ler/Time series/Hierarchical Forecasting/gross1990.pdf:pdf},
issn = {1099131X},
journal = {Journal of Forecasting},
keywords = {Composite root mean square error differential,Disaggregational methods,Forecasting,Product line,Time series analysis},
mendeley-groups = {Forecasting},
number = {3},
pages = {233--254},
title = {{Disaggregation methods to expedite product line forecasting}},
volume = {9},
year = {1990}
}

@article{Wickramasuriya2019,
abstract = {Large collections of time series often have aggregation constraints due to product or geographical groupings. The forecasts for the most disaggregated series are usually required to add-up exactly to the forecasts of the aggregated series, a constraint we refer to as “coherence.” Forecast reconciliation is the process of adjusting forecasts to make them coherent. The reconciliation algorithm proposed by Hyndman et al. (2011) is based on a generalized least squares estimator that requires an estimate of the covariance matrix of the coherency errors (i.e., the errors that arise due to incoherence). We show that this matrix is impossible to estimate in practice due to identifiability conditions. We propose a new forecast reconciliation approach that incorporates the information from a full covariance matrix of forecast errors in obtaining a set of coherent forecasts. Our approach minimizes the mean squared error of the coherent forecasts across the entire collection of time series under the assumption of unbiasedness. The minimization problem has a closed-form solution. We make this solution scalable by providing a computationally efficient representation. We evaluate the performance of the proposed method compared to alternative methods using a series of simulation designs which take into account various features of the collected time series. This is followed by an empirical application using Australian domestic tourism data. The results indicate that the proposed method works well with artificial and real data. Supplementary materials for this article are available online.},
author = {Wickramasuriya, Shanika L. and Athanasopoulos, George and Hyndman, Rob J.},
doi = {10.1080/01621459.2018.1448825},
file = {:C$\backslash$:/Users/felip/OneDrive/Documentos/Artigos a ler/Time series/Hierarchical Forecasting/wickramasuriya2018.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Aggregation,Australian tourism,Coherent forecasts,Contemporaneous error correlation,Forecast combinations,Spatial correlations},
mendeley-groups = {Forecasting/Hierarchical Forecasting},
number = {526},
pages = {804--819},
publisher = {Taylor {\&} Francis},
title = {{Optimal Forecast Reconciliation for Hierarchical and Grouped Time Series Through Trace Minimization}},
url = {https://doi.org/10.1080/01621459.2018.1448825},
volume = {114},
year = {2019}
}

@book{banerjee2014linear,
  title={Linear algebra and matrix analysis for statistics},
  author={Banerjee, Sudipto and Roy, Anindya},
  year={2014},
  publisher={Crc Press}
}

@article{schafer2005shrinkage,
  title={A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics},
  author={Sch{\"a}fer, Juliane and Strimmer, Korbinian},
  journal={Statistical applications in genetics and molecular biology},
  volume={4},
  number={1},
  year={2005},
  publisher={De Gruyter}
}

@article{Ledoit2004,
abstract = {The central message of this article is that no one should use the sample covariance matrix for portfolio optimization. It is subject to estimation error of the kind most likely to perturb a mean-variance optimizer. Instead, a matrix can be obtained from the sample covariance matrix through a transformation called shrinkage. This tends to pull the most extreme coefficients toward more central values, systematically reducing estimation error when it matters most. Statistically, the challenge is to know the optimal shrinkage intensity. Shrinkage reduces portfolio tracking error relative to a benchmark index, and sub-stantially raises the manager's realized information ratio.},
author = {Ledoit, Olivier and Wolf, Michael},
doi = {10.3905/jpm.2004.110},
file = {:C\:/Users/felip/OneDrive/Documentos/Artigos a ler/Time series/Hierarchical Forecasting/honey.pdf:pdf},
issn = {00954918},
journal = {Journal of Portfolio Management},
mendeley-groups = {Forecasting/Hierarchical Forecasting},
number = {4},
pages = {1--22},
title = {{Honey, I shrunk the sample covariance matrix}},
volume = {30},
year = {2004}
}
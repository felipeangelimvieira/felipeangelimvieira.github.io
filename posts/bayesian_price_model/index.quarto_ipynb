{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Hierarchical Bayesian Modeling of Willingness to Pay\"\n",
        "bibliography: bibliography.bib\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-depth: 4\n",
        "    toc-expand: 4\n",
        "draft: true\n",
        "author: \"Felipe Angelim\"\n",
        "date: \"2025-05-29\"\n",
        "categories: [machine learning, bayesian inference]\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "## Motivation\n",
        "\n",
        "In real-world scenarios such as pricing experiments, different groups or regions often exhibit unique behaviors. For example, customers from different regions and age groups may be willing to pay different prices for a given product.\n",
        "However, datasets can be imbalanced, and some segments may have significantly fewer observations than others. This imbalance can lead to unreliable estimates of group-specific behaviors if we model each region independently. Bayesian hierarchical models offer an elegant solution by effectively \"borrowing strength\" across groups, resulting in better-informed inferences even for underrepresented groups.\n",
        "\n",
        "In this post, we will infer the Willingness-to-pay (WTP) curve of customers:\n",
        "\n",
        "> How much does someone have to pay or\n",
        "be compensated for a change in their environment so as to be no better off or worse off after the\n",
        "change as before? (@paczkowski2018pricing)\n",
        "\n",
        "\n",
        "We will:\n",
        "\n",
        "1.  **Simulate** an imbalanced dataset representing customer purchase decisions across four groups (regions).\n",
        "2.  **Define and fit a no-pooling Bayesian model** where each region is modeled independently, and visualize its results.\n",
        "3.  **Define and fit a Bayesian hierarchical model** to capture region-specific purchase behaviors, leveraging shared hyperpriors, and visualize its results.\n",
        "4.  **Compare** the predictions from both models side-by-side.\n",
        "\n",
        "\n",
        "## 1. Simulating Imbalanced region Data\n"
      ],
      "id": "312d7216"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "# | code-summary: \"Import libraries and define utility functions\"\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import MCMC, NUTS, Predictive\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "numpyro.enable_x64()\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "\n",
        "\n",
        "# Utility Function 1: Compute Predictive Curves\n",
        "def compute_predictive_curves(p50_posterior, slope_posterior, price_grid):\n",
        "    \"\"\"\n",
        "    Computes posterior predictive samples for purchase probability curves.\n",
        "\n",
        "    Args:\n",
        "        p50_posterior (np.ndarray): Posterior samples for p50 (shape: n_samples, n_regions).\n",
        "        slope_posterior (np.ndarray): Posterior samples for slope (shape: n_samples, n_regions).\n",
        "        price_grid (np.ndarray): Grid of prices for evaluation (shape: n_prices,).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Posterior samples of purchase probabilities (shape: n_samples, n_regions, n_prices).\n",
        "    \"\"\"\n",
        "    n_samples = p50_posterior.shape[0]\n",
        "    n_regions = p50_posterior.shape[1]\n",
        "    n_prices = price_grid.shape[0]\n",
        "\n",
        "    prob_posterior_samples = np.empty((n_samples, n_regions, n_prices))\n",
        "    for i in range(n_samples):\n",
        "        # Broadcasting: p50_posterior[i] is (n_regions,), slope_posterior[i] is (n_regions,)\n",
        "        # price_grid is (n_prices,). ratio becomes (n_regions, n_prices)\n",
        "        ratio = price_grid[None, :] / p50_posterior[i][:, None]\n",
        "        prob_posterior_samples[i] = 1 / (1 + ratio ** slope_posterior[i][:, None])\n",
        "    return prob_posterior_samples\n",
        "\n",
        "\n",
        "# Utility Function 2: Summarize Posterior Probabilities\n",
        "def summarize_posterior_probs(prob_posterior_samples, q_low=0.025, q_high=0.975):\n",
        "    \"\"\"\n",
        "    Calculates mean and credible intervals for posterior probability samples.\n",
        "\n",
        "    Args:\n",
        "        prob_posterior_samples (np.ndarray): Posterior samples of probabilities.\n",
        "        q_low (float): Lower quantile for credible interval.\n",
        "        q_high (float): Upper quantile for credible interval.\n",
        "\n",
        "    Returns:\n",
        "        tuple: mean_probs, low_ci_probs, high_ci_probs\n",
        "    \"\"\"\n",
        "    mean_probs = prob_posterior_samples.mean(axis=0)\n",
        "    low_ci_probs = np.quantile(prob_posterior_samples, q_low, axis=0)\n",
        "    high_ci_probs = np.quantile(prob_posterior_samples, q_high, axis=0)\n",
        "    return mean_probs, low_ci_probs, high_ci_probs\n",
        "\n",
        "\n",
        "# Utility Function 3: Plot curves for all regions on a single Axes\n",
        "def plot_all_regions_summary(\n",
        "    price_grid,\n",
        "    mean_probs,\n",
        "    low_ci_probs,\n",
        "    high_ci_probs,\n",
        "    true_curves,\n",
        "    n_regions,\n",
        "    model_name,\n",
        "    colors_list,\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots estimated vs. true curves for all regions for a given model.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for r_idx in range(n_regions):\n",
        "        plt.plot(\n",
        "            price_grid,\n",
        "            mean_probs[r_idx],\n",
        "            color=colors_list[r_idx],\n",
        "            label=f\"Region {r_idx} ({model_name} Est.)\",\n",
        "        )\n",
        "        plt.fill_between(\n",
        "            price_grid,\n",
        "            low_ci_probs[r_idx],\n",
        "            high_ci_probs[r_idx],\n",
        "            color=colors_list[r_idx],\n",
        "            alpha=0.3,\n",
        "        )\n",
        "        if true_curves is not None:\n",
        "            plt.plot(\n",
        "                price_grid,\n",
        "                true_curves[r_idx],\n",
        "                linestyle=\"--\",\n",
        "                linewidth=2,\n",
        "                color=colors_list[\n",
        "                    r_idx\n",
        "                ],  # Using same color for true curve for visual grouping\n",
        "                label=f\"Region {r_idx} (True)\",\n",
        "            )\n",
        "    plt.xlabel(\"Price\")\n",
        "    plt.ylabel(\"Purchase Probability\")\n",
        "    plt.title(\n",
        "        f\"{model_name} Model: Estimated vs. True Purchase Probability by Region\\nwith 95% Credible Intervals\"\n",
        "    )\n",
        "    plt.legend(\n",
        "        loc=\"center right\", bbox_to_anchor=(1.45, 0.5)\n",
        "    )  # Adjusted for more space\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "id": "1e2397b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We simulate a dataset of 400 purchase decision samples distributed unevenly across four regions. This data could be coming from a survey conducted with current clients, to analyze how much they would pay to change their subscription or product to new option. Specifically, region 3 has significantly fewer observations, representing realistic data imbalance.\n"
      ],
      "id": "e37d7456"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "# | code-summary: \"Generate imbalanced region data\"\n",
        "# ---------- Simulated data (with imbalanced regions) ----------\n",
        "key = jax.random.PRNGKey(0)\n",
        "# split the key so we get fresh randomness for price, region, and labels\n",
        "key, key_price, key_region, key_y = jax.random.split(key, 4)\n",
        "\n",
        "n_regions, n_obs = 4, 200\n",
        "true_p50 = jnp.array([10.0, 12.0, 9.0, 15.0])\n",
        "true_n = jnp.array([2.0, 1.8, 2.5, 1.6]) * 4\n",
        "\n",
        "# 1) sample prices as before\n",
        "price = jax.random.uniform(key_price, (n_obs,), minval=0.0, maxval=20.0)\n",
        "\n",
        "# 2) define region probabilities (last region only 5%)\n",
        "region_probs = jnp.array([0.42, 0.2, 0.35, 0.03])\n",
        "region_idx = jax.random.choice(\n",
        "    key_region, jnp.arange(n_regions), shape=(n_obs,), p=region_probs\n",
        ")\n",
        "\n",
        "# 3) generate “true” purchase probabilities and observations\n",
        "p_true = 1 / (1 + (price / true_p50[region_idx]) ** true_n[region_idx])\n",
        "y = dist.Bernoulli(probs=p_true).sample(key_y)"
      ],
      "id": "ccc42a54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.DataFrame(\n",
        "    data={\"y\" : y, \"region_idx\" : region_idx}\n",
        ")"
      ],
      "id": "ebcf0642",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "# | code-summary: \"Prepare common variables for plotting\"\n",
        "# Define price_grid, true_curves and colors early as they are needed for multiple plots\n",
        "price_grid = np.linspace(0, 20, 200)\n",
        "true_curves = np.vstack(\n",
        "    [1 / (1 + (price_grid / tp50) ** tn) for tp50, tn in zip(true_p50, true_n)]\n",
        ")\n",
        "cmap = plt.get_cmap(\"tab10\")\n",
        "plot_colors = [cmap(i) for i in range(n_regions)]"
      ],
      "id": "e09b5e24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Without Pooling (No-Pooling Approach)\n",
        "\n",
        "\n",
        "We begin by fitting a **no-pooling** model. We consider a logistic-like curve for the purchave probability:\n",
        "\n",
        "$$\n",
        "p_i = \\frac{1}{1 + \\left(\\frac{\\text{price}}{p50_i}\\right)^{\\text{slope}_i}}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- **`p50_i`** is the price at which the purchase probability is 50% for region `i`.\n",
        "- **`slope_i`** controls the steepness of the curve for region `i`.\n",
        "\n",
        "This approach treats each region entirely independently, meaning each region will have its own separate prior on `p50` and `slope`, without sharing information across groups. This will serve as a baseline to understand the behavior of each region when modeled in isolation.\n",
        "\n",
        "$$\n",
        "y_i \\;\\sim\\; \\mathrm{Bernoulli}(p_i) \n",
        "$$\n",
        "\n",
        "$$\n",
        "p_{50} \\;\\sim\\; \\mathrm{HalfNormal}(20), \n",
        "$$\n",
        "\n",
        "$$\n",
        "slope \\;\\sim\\; \\mathrm{HalfNormal}(1000)\n",
        "$$\n"
      ],
      "id": "bbe20d9b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "# | code-summary: \"Define the no-pooling model\"\n",
        "def model_no_pool(price, region, n_regions=4, y=None):\n",
        "    # Independent priors per region (no hyperpriors)\n",
        "    with numpyro.plate(\"regions\", n_regions):\n",
        "        slope_i = numpyro.sample(\"slope_i_inner\", dist.HalfNormal(1000.0))\n",
        "        p50_i = numpyro.sample(\"p50_i\", dist.HalfNormal(20.0))\n",
        "\n",
        "    slope_i = numpyro.deterministic(\"slope_i\", jnp.log1p(slope_i))\n",
        "\n",
        "    p = 1 / (1 + (price / p50_i[region]) ** slope_i[region])\n",
        "    with numpyro.plate(\"observations\", len(price)):\n",
        "        numpyro.sample(\"obs\", dist.Bernoulli(probs=p), obs=y)"
      ],
      "id": "200d868d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "# | code-summary: \"Run inference for the no-pooling model\"\n",
        "# Run inference for no-pooling model\n",
        "nuts_np = NUTS(model_no_pool)\n",
        "mcmc_np = MCMC(nuts_np, num_warmup=1000, num_samples=2000, num_chains=4)\n",
        "key, k_np = jax.random.split(key) # JAX PRNG key splitting\n",
        "mcmc_np.run(k_np, price=price, region=region_idx, n_regions=n_regions, y=y)\n",
        "samples_np = mcmc_np.get_samples()"
      ],
      "id": "d9f44b24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing No-Pooling Model Estimates\n",
        "We now visualize the estimated purchase probability curves from the no-pooling model for each region, along with their 95% credible intervals and the true underlying curves."
      ],
      "id": "96c1bb35"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "# | code-summary: \"Process and plot no-pooling model results\"\n",
        "# Process and plot no-pooling results\n",
        "p50_np_posterior = np.array(samples_np[\"p50_i\"])\n",
        "slope_np_posterior = np.array(samples_np[\"slope_i\"])\n",
        "\n",
        "prob_np_posterior = compute_predictive_curves(p50_np_posterior, slope_np_posterior, price_grid)\n",
        "mean_np, low_np, high_np = summarize_posterior_probs(prob_np_posterior)\n",
        "\n",
        "plot_all_regions_summary(\n",
        "    price_grid, mean_np, low_np, high_np, true_curves, \n",
        "    n_regions, \"No-Pooling\", colors_list=plot_colors\n",
        ")"
      ],
      "id": "5de81868",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Bayesian Hierarchical Model\n",
        "\n",
        "Our hierarchical Bayesian model allows each region to have its own logistic-like purchase probability curve. Each region-specific curve is defined by two parameters:\n",
        "\n",
        "* **`p50`**: Price at which the purchase probability is 50%.\n",
        "* **`slope`**: Controls the steepness of the curve.\n",
        "\n",
        "These parameters vary across regions and are drawn from hyperpriors, capturing similarities and differences across groups. This approach contrasts with the no-pooling model by allowing regions to \"borrow strength\" from each other, which can be particularly useful for imbalanced data.\n",
        "\n",
        "$$\n",
        "\\sigma_{p_{50}} \\;\\sim\\; \\mathrm{HalfNormal}(20), \n",
        "\\quad\n",
        "\\sigma_{\\text{slope}} \\;\\sim\\; \\mathrm{HalfNormal}(1000)\n",
        "$$\n",
        "\n",
        "$$\n",
        "p_{50,j} \\;\\sim\\; \\mathrm{HalfNormal}\\bigl(\\sigma_{p_{50}}\\bigr), \n",
        "\\quad \n",
        "\\tilde{\\lambda}_j \\;\\sim\\; \\mathrm{HalfNormal}\\bigl(\\sigma_{\\text{slope}}\\bigr), \n",
        "\\quad \n",
        "slope_{j} \\;=\\; \\log\\bigl(1 + \\tilde{\\lambda}_j\\bigr), \n",
        "\\quad j=0,\\dots,J-1 \\\\[1ex]\n",
        "$$\n"
      ],
      "id": "5bfbeb10"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "# | code-summary: \"Define the hierarchical model\"\n",
        "def model(price, region, n_regions=4, y=None):\n",
        "    N = len(price)\n",
        "\n",
        "    # Hyperpriors for variability among regions\n",
        "    sigma_slope = numpyro.sample(\"sigma_slope\", dist.HalfNormal(1000.0))\n",
        "    sigma_p50 = numpyro.sample(\"sigma_p50\", dist.HalfNormal(20.0))\n",
        "\n",
        "    with numpyro.plate(\"regions\", n_regions):\n",
        "        slope_i = numpyro.sample(\"mu_i\", dist.HalfNormal(sigma_slope)) # mu_i in example, corresponds to a mean for slope component\n",
        "        p50_i = numpyro.sample(\"p50_i\", dist.HalfNormal(sigma_p50))   # p50_i in example\n",
        "\n",
        "    # Deterministic transformation for slopes (e.g. log1p for positivity if HalfNormal gives small values near zero effectively)\n",
        "    # The original had jnp.log1p(slope_i) for 'slopes'.\n",
        "    # If 'mu_i' from HalfNormal(sigma_slope) is directly the slope, then no transform needed or HalfNormal for slope itself.\n",
        "    # The original model 'slopes = numpyro.deterministic(\"slopes\", jnp.log1p(slope_i))' with 'slope_i' sampled as 'mu_i'.\n",
        "    # This implies 'mu_i' is not the final slope but a parameter for it. Let's stick to original.\n",
        "    slopes = numpyro.deterministic(\"slopes\", jnp.log1p(slope_i)) \n",
        "    p50s = numpyro.deterministic(\"p50s\", p50_i) # p50_i is directly used as p50s\n",
        "\n",
        "    p = 1 / (1 + (price / p50s[region]) ** slopes[region])\n",
        "    numpyro.deterministic(\"p\", p)\n",
        "\n",
        "    with numpyro.plate(\"observations\", N):\n",
        "        numpyro.sample(\"obs\", dist.Bernoulli(probs=p), obs=y)"
      ],
      "id": "d268e5ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "# | code-summary: \"Render the hierarchical model structure\"\n",
        "model_args = (price, region_idx, n_regions, y) # Ensure n_regions is correctly passed\n",
        "numpyro.render_model(model, model_args=model_args)"
      ],
      "id": "1a329b3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Running Bayesian Inference for the Hierarchical Model\n",
        "\n",
        "We use the No-U-Turn Sampler (NUTS) provided by NumPyro to infer the posterior distributions of our hierarchical model parameters:\n"
      ],
      "id": "9f864ca0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "# | code-summary: \"Run inference for the hierarchical model\"\n",
        "# Inference using NUTS\n",
        "key, k_mcmc, _ = jax.random.split(key, 3) # JAX PRNG key splitting\n",
        "\n",
        "nuts = NUTS(model)\n",
        "mcmc = MCMC(nuts, num_warmup=1000, num_samples=2000, num_chains=4)\n",
        "mcmc.run(k_mcmc, price=price, region=region_idx, n_regions=n_regions, y=y)\n",
        "mcmc.print_summary()\n",
        "samples_h = mcmc.get_samples() # Renamed to samples_h for clarity"
      ],
      "id": "ba5523a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Hierarchical Model Estimates\n",
        "Similarly, we visualize the estimated purchase probability curves from the hierarchical model."
      ],
      "id": "77643646"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "# | code-summary: \"Process and plot hierarchical model results\"\n",
        "# Process and plot hierarchical results\n",
        "p50_h_posterior = np.array(samples_h[\"p50s\"])\n",
        "slope_h_posterior = np.array(samples_h[\"slopes\"])\n",
        "\n",
        "prob_h_posterior = compute_predictive_curves(p50_h_posterior, slope_h_posterior, price_grid)\n",
        "mean_h, low_h, high_h = summarize_posterior_probs(prob_h_posterior)\n",
        "\n",
        "plot_all_regions_summary(\n",
        "    price_grid, mean_h, low_h, high_h, true_curves, \n",
        "    n_regions, \"Hierarchical\", colors_list=plot_colors\n",
        ")"
      ],
      "id": "08b65055",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Comparing Model Predictions\n",
        "\n",
        "Now we compare the predictions from both models—no-pooling and hierarchical—side-by-side for each region. This allows us to directly observe the effect of hierarchical pooling, especially for regions with sparse data.\n"
      ],
      "id": "a777b721"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "# | code-summary: \"Plot side-by-side comparison of models per region\"\n",
        "# mean_h, low_h, high_h are from hierarchical model processing\n",
        "# mean_np, low_np, high_np are from no-pooling model processing\n",
        "# true_curves, price_grid, plot_colors are already defined\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8), sharex=True, sharey=True)\n",
        "axes = axes.flatten()\n",
        "for r_idx, ax in enumerate(axes):\n",
        "    # True underlying curve\n",
        "    ax.plot(price_grid, true_curves[r_idx], color=\"black\", linewidth=3, label=\"True\")\n",
        "    # Hierarchical model\n",
        "    ax.plot(price_grid, mean_h[r_idx], color=plot_colors[r_idx], label=\"Hierarchical\")\n",
        "    ax.fill_between(price_grid, low_h[r_idx], high_h[r_idx], color=plot_colors[r_idx], alpha=0.3)\n",
        "    # No-pooling model\n",
        "    ax.plot(price_grid, mean_np[r_idx], color=\"gray\", linestyle=\"--\", label=\"No-Pooling\")\n",
        "    ax.fill_between(price_grid, low_np[r_idx], high_np[r_idx], color=\"gray\", alpha=0.2)\n",
        "    ax.set_title(f\"Region {r_idx}\")\n",
        "    ax.set_xlabel(\"Price\")\n",
        "    ax.set_ylabel(\"Purchase Probability\")\n",
        "    ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "c9a98fcb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key observations**:\n",
        "\n",
        "* For well-sampled regions (e.g., regions 0, 1, 2), both models give similar posterior means. However, the hierarchical model often shows tighter credible intervals due to the partial pooling effect, reflecting more certain estimates informed by the overall data structure.\n",
        "* For the underrepresented region (region 3), the no-pooling model's credible band is much wider and more variable, reflecting high uncertainty when data are scarce. In contrast, the hierarchical model \"borrows strength\" from other regions, yielding a more stable and often more accurate estimate, with narrower credible intervals than the no-pooling approach.\n",
        "\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This analysis demonstrates the robustness of Bayesian hierarchical modeling in situations with imbalanced datasets. By leveraging shared hyperpriors, hierarchical models allow different groups (regions, in this case) to inform each other. This partial pooling leads to more reliable inferences, especially for groups with limited data. In contrast, a no-pooling approach, while straightforward, can suffer from high variance and uncertainty for underrepresented groups. Hierarchical models are thus essential tools in many fields where understanding subgroup behavior under uncertainty is critical, providing a balance between modeling each group independently and pooling all data together."
      ],
      "id": "ce0a44d8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/felipeangelim/Workspace/felipeangelimvieira.github.io/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
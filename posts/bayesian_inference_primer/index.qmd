---
title: "Bayesian Inference - What, When, why, how?"
image: thumbnail.png
author: "Felipe Angelim"
date: "2025-05-27"
categories: [machine learning, bayesian inference]
jupyter: python3
---


## Motivation

Before we start, let's clarify the difference between two important concepts in statistics: **confidence intervals** and **credible intervals**.

If $[A, B]$ is an interval generated by a model, and $\theta$ is the parameter of interest, which of the following is bayesian and which is frequentist statement?

> **A. There is a 95% probability that the true quantity $\theta$ lies in $[A, B]$**
> 
> **B. There is 95% chance that $[A, B]$ contains the true quantity $\theta$**


::: {.callout-tip collapse="true"}
## Answer
The first is a Bayesian, the second is a frequentist statement.

The frequentist interval tells us that, if we repeat the experiment say 100 times, 95 of the constructed intervals will contain the true parameter value. The Bayesian interval tells us that, given the data we have, there is a 95% chance that the true parameter value lies in that interval. The key difference is that the bayesian credible interval conditions on the data, while the frequentist confidence interval takes into account the randomness of the data generation process on the measurements.
 
:::

One of the most intuitive explanations of the difference between both perspectives is the one presented by [Jake VanderPlas in his talk in 2014](
    https://www.youtube.com/watch?v=KhAUfqhLakw
).

Consider this simple analogy: imagine you are trying to estimate the height of a tree. The Frequentist approach would be to take a sample of trees, measure their heights, and then calculate a confidence interval based on that sample. The Bayesian approach, on the other hand, would involve taking into account your prior knowledge about the height of trees in general, and then updating that knowledge based on the sample you took. The intervals of the frequentist method would tell that this measurement procedure has 95% chance to contain the true average height of the trees, while the bayesian method would tell that, given the data we have, there is a 95% chance that the true average height of the trees lies in the interval.

```{python}
# | label: intervals
# | fig-cap: "Bayesian vs Frequentist intervals, as in [Jake VanderPlas talk in 2014](https://www.youtube.com/watch?v=KhAUfqhLakw)"
# | echo: false

import matplotlib.pyplot as plt
import numpy as np

# Set random seed for reproducibility
np.random.seed(42)

# Generate synthetic data
bayesian_params = np.random.normal(loc=0, scale=1, size=(100, 2))
frequentist_center = np.array([0, -5])
frequentist_intervals = [
    frequentist_center + np.random.normal(scale=2, size=2) for _ in range(20)
]

# Create side-by-side plots with white background
fig, (ax_bayes, ax_freq) = plt.subplots(1, 2, figsize=(12, 6))
fig.patch.set_facecolor("white")

# --- Bayesian Credible Region ---
ax_bayes.set_facecolor("white")
ax_bayes.scatter(
    bayesian_params[:, 0], bayesian_params[:, 1], color="orange", label="Parameter"
)
bayesian_ellipse = plt.Circle(
    (0, 0), 2.5, color="steelblue", alpha=0.5, label="Interval"
)
ax_bayes.add_patch(bayesian_ellipse)

ax_bayes.set_title("Bayesian Credible Region", color="black", fontsize=14)
ax_bayes.legend(loc="upper right", fontsize=10)
ax_bayes.set_xlim(-6, 6)
ax_bayes.set_ylim(-6, 6)
ax_bayes.axis("off")

# --- Frequentist Confidence Interval ---
ax_freq.set_facecolor("white")
for center in frequentist_intervals:
    ellipse = plt.Circle(center, 2.5, color="steelblue", alpha=0.3)
    ax_freq.add_patch(ellipse)
ax_freq.scatter(
    [frequentist_center[0]], [frequentist_center[1]], color="orange", label="Parameter"
)

ax_freq.set_title("Frequentist Confidence Interval", color="black", fontsize=14)
ax_freq.legend(loc="upper right", fontsize=10)
ax_freq.set_xlim(-6, 6)
ax_freq.set_ylim(-10, 2)
ax_freq.axis("off")

plt.tight_layout()
plt.show()
```

This subtle difference leads to difference answers, in some cases, and for a given question we should be careful to choose the right approach. Here are some questions that a credible interval may answer better:

| # | Bayesian | Frequentist | Comments |
|---|----------|-------------|----------|
| 1 | “Given only three months of sales data for a brand-new SKU, how likely is it to exceed 1,000 units next quarter?” | "Based on three months of data, what is a 95 % prediction interval for next-quarter sales, and does that interval lie wholly above 1 000?" | The frequentist approach does not allow us to incorporate prior knowledge, or compute the average outstock. |
* 

## Basics of Bayesian Inference

In Bayesian Inference, we are
interested in finding out the distribution $P(\theta|X)$ of our parameters $\theta$,
given our data $X$. We consider that the parameters are random variables, where their distribution represent the amount of uncertainty we have on the. 

Bayesian inference derives from the simple Bayes' rule:

$$
\underbrace{P(\theta|X)}_{\text{Posterior}} = \frac{P(X|\theta)P(\theta)}{P(X)}
$$

That, for all practical purposes, can be simplified to:

$$
 \underbrace{P(\theta|X)}_{\text{Posterior}} \propto \underbrace{P(X|\theta)}_{\text{Likelihood}} \underbrace{P(\theta)}_{\text{Prior}}
$$

This "$\propto$" symbol indicates "proportional to", and proportionality is simpler, tractable and enough to find the posterior. We don't need to know the exact probability of $P(\theta|X)$ to estimate such distribution, as we will see, we need just to be able to answer how much a given parameter value is probable in comparison to other values. The denominator $P(X)$ serves as a normalization term, to guarantee that the posterior integrates to one,
and since it is independent of $\theta$ - the quantity we are interested in - we can just ignore it.

So, we can interpret each term as:

* Likelihood $P(X|\theta)$: probability of observing the data given parameters. The model of how the world produces data from parameters.
* Prior distribution $P(\theta)$: probability of seeing a set of parameters, not conditioned on the data. This represent our prior beliefs.
* Posterior distribution $P(\theta|X)$: probability of the parameters, given the data. 


This rule **connects** any prior belief one has about the parameters to what their distribution must be according to the data. Where either the prior or the likelihood is zero, the posterior probability is also zero. So the prior can also work to restrict the domain of our parameters.

An standard example is toin cossing. Let $\theta$, the parameter of our model, be the bias of a coin (probability of landing heads), and $X = (K,N)$ the number of heads and total trials.

* The prior distribution should reflect our initial guesses of what the bias of the coin should be.
The probability of landing heads should lie between 0 and 1 ($\theta \in (0, 1)$), and a natural
choice of prior here is the [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution), that has its domain in this interval.
  
* The likelihood is the mathematical rule that tells us how the world produces what we see. **It’s the bridge between theory and observation**. For a toin coss, a natural rule to describe the number
of heads $X$  is binomial distribution:

$$
X|\theta \sim \text{Binomial}(n, k) = \binom{n}{k} \,p^k (1-p)^{\,n-k}
$$

* The posterior will be our final belief on the values of $\theta$. It will reflect both the prior belief and the likelihood of the data.


For some situations, we can analitically compute the posterior distribution, by replacing the likelihood and prior in Bayes' rule equation. This coin-toss example is one of them, so we can easily build an interactive tools to visualize it.


::: {.callout-tip}

The interactive view below let's you play with the prior and posterior distributions of a coin toss experiment. 

Note how, for $Beta(1,1)$, the prior is uniform. This means that we have no prior knowledge about the coin bias (we call this uninformative prior), and only the likelihood term will influence the posterior. 
:::

```{ojs}
//| echo: false
// Cell 1: Load jStat via dynamic import
jStat = require("jStat@latest")

// Cell 2: Interactive parameter ranges (Inputs is preloaded)
viewof alpha = Inputs.range([1, 20], {step: 1, value: 1, label: "Alpha (α)"});
viewof beta  = Inputs.range([1, 20], {step: 1, value: 1, label: "Beta (β)"});
viewof n     = Inputs.range([1, 200], {step: 1, value: 100, label: "Trials (n)"});
viewof k     = Inputs.range([0, n],    {step: 1, value: 60, label: "Heads (k)"});

// Cell 3: Compute θ grid and densities (Plot is preloaded)
thetaValues = Array.from({length: 200}, (_, i) => i / 199);

priorDist = thetaValues.map(t => ({
  theta: t,
  density: jStat.beta.pdf(t, alpha, beta),
  type: "Prior"
}));

posteriorDist = thetaValues.map(t => ({
  theta: t,
  density: jStat.beta.pdf(t, alpha + k, beta + (n - k)),
  type: "Posterior"
}));

// Cell 4: Plot prior and posterior
Plot.plot({
  width: 600,
  height: 400,
  x: {label: "θ"},
  y: {label: "Density"},
  color: {legend: true},
  marks: [
    Plot.line(priorDist,    {x: "theta", y: "density", stroke: "type", strokeWidth: 2}),
    Plot.line(posteriorDist,{x: "theta", y: "density", stroke: "type", strokeWidth: 2})
  ]
});
```

### Untractable posteriors 

In other situations (most of them), developing the equations does not lead to an analytical solution.
In such cases, we can use alternative methods to approximate the posterior distribution.


#### Maximum A Posteriori (MAP)

The Maximum A Posteriori (MAP) estimate is the mode of the posterior distribution: the value of $\theta$ that maximizes the posterior probability density function.


```{python}
# | echo: False
from IPython.display import HTML
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# Define θ range
theta = np.linspace(-5, 5, 500)
prior = np.exp(-0.5 * (theta) ** 2)  # Standard normal prior
likelihood = np.exp(-0.5 * (theta - 2) ** 2 / 0.5**2)  # Likelihood centered at θ=2

posterior = prior * likelihood  # Unnormalized posterior

# Normalize for visualization
prior /= np.max(prior)
likelihood /= np.max(likelihood)
posterior /= np.max(posterior)

fig, ax = plt.subplots()
(line_prior,) = ax.plot([], [], label="Prior")
(line_likelihood,) = ax.plot([], [], label="Likelihood")
(line_posterior,) = ax.plot([], [], label="Posterior (unnormalized)")
(point,) = ax.plot([], [], "ro", label="MAP estimate")


def init():
    ax.set_xlim(-5, 5)
    ax.set_ylim(0, 1.2)
    ax.legend()
    return line_prior, line_likelihood, line_posterior, point


def update(frame):
    if frame == 0:
        line_prior.set_data(theta, prior)
        line_likelihood.set_data([], [])
        line_posterior.set_data([], [])
        point.set_data([], [])
    elif frame == 1:
        line_likelihood.set_data(theta, likelihood)
    elif frame == 2:
        line_posterior.set_data(theta, posterior)
    elif frame == 3:
        map_estimate = theta[np.argmax(posterior)]
        map_value = posterior.max()
        point.set_data([map_estimate], [map_value])
    return line_prior, line_likelihood, line_posterior, point


ani = FuncAnimation(fig, update, frames=4, init_func=init, blit=True, repeat=False)
plt.close()
HTML(ani.to_jshtml())
```

Although not a true bayesian inferece, MAP can provide us point estimates that balance the prior and likelihood. The posterior $P(\theta|X)$  is treated as a function whose maximum we want to find, and
due to amazing libraries such as numpyro, and jax, we
can leverage autodiff to compute the gradient of the posterior, and rapidly estimate it.


```{python}
# | echo: False
# Define the parameter range
theta = np.linspace(-5, 5, 500)

# Define prior, likelihood, and unnormalized posterior
prior = np.exp(-0.5 * theta**2)
likelihood = np.exp(-0.5 * (theta - 2) ** 2 / (0.5**2))
posterior = prior * likelihood


# Compute gradient of the log-posterior analytically
def grad_log_post(t):
    return -t - (t - 2) / (0.5**2)


# Perform gradient ascent to generate trajectory of theta values
lr = 0.06
num_steps = 30
thetas = [-4.0]
for _ in range(num_steps - 1):
    t = thetas[-1]
    t_new = t + lr * grad_log_post(t)
    thetas.append(t_new)

# Normalize posterior for plotting
posterior_norm = posterior / np.max(posterior)

# Set up the figure and axis
fig, ax = plt.subplots()
ax.set_xlim(-5, 5)
ax.set_ylim(0, 1.2)
ax.plot(theta, posterior_norm, label="Unnormalized Posterior")
(point,) = ax.plot([], [], "o", markersize=10)
ax.set_xlabel("θ")
ax.set_ylabel("Density")
ax.legend()


# Animation update function
def update(i):
    point.set_data([thetas[i]], [np.interp(thetas[i], theta, posterior_norm)])
    return (point,)


# Create animation
ani = FuncAnimation(fig, update, frames=len(thetas), blit=True)
plt.close()
HTML(ani.to_jshtml())
```

The **Maximum Likelihood Estimate (MLE)** would be a frequentist approach similar to MAP, but, in this case, we completely ignore the prior, and optimize the likelihood function. In this sense, you can think of
MAP as a regularized version of MLE, where the prior acts as a regularization term.

Indeed, in many cases, **the MAP estimate is equivalent to the MLE estimate with a regularization term!**. For example, the famous Ridge and Lasso regressions, that penalize coefficients far from zero, can be seen as MAP estimates with Gaussian and Laplace priors centered on zero, respectively. As the parameter value increases in magnitude, the prior reduces the posterior probability, effectively penalizing large coefficients. This implies that another way to see such regression methods in application of your prior beliefs about the parameters being close to zero.

#### Markov Chain Monte Carlo (MCMC)

MAP provides a point estimate, but we may be
interested in the whole posterior distribution, not just a single point, to be
able to measure risks and other quantities. However, the posterior distribution maybe impossible to compute analitically. This is where MCMC comes in. 

Breaking down the name, Monte Carlo is similar to trial and error methods, seasoned with randomness; Markov Chain means we are
interested in sequences of random variables, where the next variable in the sequence
depends only on the current one, not on the previous ones. Basically, if we could reduce MCMC explanation to few words, we could say that MCMC tries to take a lot of samples from $P(\theta|X)$, based on trial and error, and the accepted samples will be the posterior distribution.****

## Why?

Bayesian inference is not a familiar topic for many data scientist practitioners,
but provides a rich set of toolkits for data scientists and businesses that know it. 
Two reasons make it attractive:

* In the lack of large datasets, good and informative **regularization** is key to avoid obtaining bad estimates from your model. The *priors* are a natural way
of regularizing a model.
* MCMC samples provides an elegant solution to accessing the risks of the outputs a model, or any transformations of it (such as cumulative values).

If the words "bayesian" and "inference" make you afraid: do not worry.
 We will see that, if you already fitted a ridge or lasso regression, you already did
something bayesian. We could also create a gradient of "how" bayesian 




*This blog post is based on a talk presented at Galp. This post is not meant to be seen as part of "bayesian vs frequentist" rivalry.
I aim to point at some examples of problems where bayesian methodologies can better answer the business **questions** and provide extra insights, that similar frequentist methods maybe also could, but not in a natural or easy way as with
bayesian logic.*